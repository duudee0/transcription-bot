from common.base_service import BaseService
from common.models import TaskMessage, ResultData
from fastapi import HTTPException
import numpy as np
from typing import Dict, Any, List
import os

# –î–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å sentence-transformers
try:
    from sentence_transformers import SentenceTransformer
    import torch
except ImportError:
    # Fallback –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    pass

class EmbeddingService(BaseService):
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Ç–µ–∫—Å—Ç–∞"""
    
    def __init__(self):
        super().__init__("embedding-service", "1.0")
        self.model = None
        self.model_name = os.getenv("MODEL_NAME", "sentence-transformers/all-MiniLM-L6-v2")
        self._load_model()
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        try:
            # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
            self.model = SentenceTransformer(self.model_name)
            print(f"‚úÖ Model loaded: {self.model_name}")
        except Exception as e:
            print(f"‚ö†Ô∏è Could not load model {self.model_name}: {e}")
            print("üîß Using dummy embeddings for testing")
    
    async def _validate_task(self, task_message: TaskMessage):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–¥–∞—á –¥–ª—è embedding service"""
        if task_message.data.task_type not in ["generate_embeddings", "get_embedding_dim"]:
            raise HTTPException(
                status_code=400, 
                detail=f"Unsupported task type: {task_message.data.task_type}"
            )
        
        if task_message.data.task_type == "generate_embeddings":
            texts = task_message.data.input_data.get("texts", [])
            if not texts or not isinstance(texts, list):
                raise ValueError("Texts list is required for generate_embeddings task")
    
    async def _process_task_logic(self, task_message: TaskMessage) -> ResultData:
        """–õ–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        task_type = task_message.data.task_type
        
        if task_type == "generate_embeddings":
            return await self._generate_embeddings(task_message.data.input_data)
        elif task_type == "get_embedding_dim":
            return await self._get_embedding_dim()
    
    async def _generate_embeddings(self, input_data: Dict[str, Any]) -> ResultData:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤"""
        texts = input_data.get("texts", [])
        normalize = input_data.get("normalize", True)
        
        try:
            if self.model:
                # –†–µ–∞–ª—å–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
                embeddings = self.model.encode(texts, normalize_embeddings=normalize)
                embeddings_list = embeddings.tolist()
            else:
                # –¢–µ—Å—Ç–æ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ (–∑–∞–≥–ª—É—à–∫–∞)
                embeddings_list = self._generate_dummy_embeddings(texts, 384)
            
            return ResultData(
                success=True,
                result={
                    "embeddings": embeddings_list,
                    "texts": texts,
                    "dimension": len(embeddings_list[0]) if embeddings_list else 0,
                    "count": len(embeddings_list)
                },
                execution_metadata={
                    "service": "embedding-service",
                    "model": self.model_name if self.model else "dummy",
                    "normalized": normalize
                }
            )
            
        except Exception as e:
            return ResultData(
                success=False,
                error_message=f"Embedding generation failed: {str(e)}",
                execution_metadata={"service": "embedding-service", "error": True}
            )
    
    async def _get_embedding_dim(self) -> ResultData:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        if self.model:
            dim = self.model.get_sentence_embedding_dimension()
        else:
            dim = 384  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        
        return ResultData(
            success=True,
            result={"dimension": dim},
            execution_metadata={"service": "embedding-service"}
        )
    
    def _generate_dummy_embeddings(self, texts: List[str], dimension: int) -> List[List[float]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        embeddings = []
        for i, text in enumerate(texts):
            # –ü—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è "—ç–º–±–µ–¥–¥–∏–Ω–≥" –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            embedding = [float((hash(text + str(i)) % 1000) / 1000) for _ in range(dimension)]
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            norm = sum(x*x for x in embedding) ** 0.5
            normalized = [x/norm for x in embedding]
            embeddings.append(normalized)
        return embeddings

# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–∞
if __name__ == "__main__":
    service = EmbeddingService()
    service.run(port=int(os.getenv("PORT", 8004)))