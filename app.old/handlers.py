from aiogram import Bot, types, F, Router
from aiogram.filters import Command, CommandStart
from aiogram.types import Message, CallbackQuery, BufferedInputFile
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from pyannote.audio import Pipeline
from transformers import pipeline
import app.keyboards as kb
import whisper
import tempfile
import os
from moviepy import VideoFileClip
from pydub import AudioSegment
from app.database import db
from typing import Optional
from TTS.api import TTS
import soundfile as sf
from transformers import AutoModelForSeq2SeqLM
from dotenv import load_dotenv

load_dotenv()

last_text_for_tts = {}

class UserState(StatesGroup):
    waiting_for_tts = State()
    waiting_for_transcribe = State()

tts = TTS("tts_models/multilingual/multi-dataset/xtts_v2")
model = whisper.load_model("medium")
diarization_pipeline = Pipeline.from_pretrained(
    "pyannote/speaker-diarization",
    use_auth_token=os.getenv('HF_TOKEN')
)
router = Router()

last_transcription = {}
last_raw_transcription = {}

def transcribe_and_diarize(audio_file):
    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
    result = model.transcribe(audio_file, fp16=False)
    segments = result["segments"]
    raw_text = result["text"].strip()
    
    # –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è
    diarization = diarization_pipeline(audio_file)
    
    # –°–ø–∏—Å–æ–∫ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –¥–∏–∫—Ç–æ—Ä–æ–≤
    speaker_intervals = []
    for turn, _, speaker in diarization.itertracks(yield_label=True):
        speaker_intervals.append({
            'start': turn.start,
            'end': turn.end,
            'speaker': speaker
        })
    
    speaker_intervals.sort(key=lambda x: x['start'])
    
    final_transcript = []
    current_segments = []
    
    for segment in segments:
        start_time = segment["start"]
        end_time = segment["end"]
        text = segment["text"].strip()
        
        speaker = None
        best_match = None
        best_overlap = 0

        for interval in speaker_intervals:
            overlap = min(end_time, interval['end']) - max(start_time, interval['start'])
            if overlap > best_overlap and overlap > 0:
                best_overlap = overlap
                best_match = interval['speaker']

        speaker = best_match if best_match else "–ù–ï–ò–ó–í–ï–°–¢–ù–´–ô_–î–ò–ö–¢–û–†"
        
        current_segments.append({
            'speaker': speaker,
            'text': text,
            'start': start_time,
            'end': end_time
        })
    
    if current_segments:
        current_speaker = current_segments[0]['speaker']
        combined_text = current_segments[0]['text']
        
        for i in range(1, len(current_segments)):
            if current_segments[i]['speaker'] == current_speaker:
                combined_text += " " + current_segments[i]['text']
            else:
                final_transcript.append(f"{current_speaker}: {combined_text}")
                current_speaker = current_segments[i]['speaker']
                combined_text = current_segments[i]['text']
        
        final_transcript.append(f"{current_speaker}: {combined_text}")
    
    return "\n".join(final_transcript), raw_text

@router.message(CommandStart())
async def cmd_start(message: Message):
    await message.answer(
        f'*–ë–æ—Ç —Å–æ–∑–¥–∞–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∞—É–¥–∏–æ –∏ —Ç–µ–∫—Å—Ç–æ–º.*\n'
        f'–ò–º–µ–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏:\n\n'
        f'üí¨*–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è* - –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞—É–¥–∏–æ –∏ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—ã –≤ —Ç–µ–∫—Å—Ç.\n–ï–≥–æ —Ç–∞–∫–∂–µ –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.\n\n' 
        f'üë•*–î–∏–∞—Ä–∏–∑–∞—Ü–∏—è* - –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫—Ç–æ –∏–∑ —Å–ø–∏–∫–µ—Ä–æ–≤ —á—Ç–æ —Å–∫–∞–∑–∞–ª.\n–ò–¥–µ–∞–ª—å–Ω–æ –¥–ª—è —Ä–∞–∑–±–æ—Ä–∞ –∏–Ω—Ç–µ—Ä–≤—å—é, —Å–æ–≤–µ—â–∞–Ω–∏–π –∏ –ø–æ–¥–∫–∞—Å—Ç–æ–≤.\n\n'
        f'‚úÇÔ∏è*–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è* - —Å–æ–∫—Ä–∞—â–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –≥–ª–∞–≤–Ω–æ–µ.\n–ü–æ–ª–µ–∑–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –æ–∑–Ω–∞–∫–æ–º–ª–µ–Ω–∏—è —Å –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Å–º—ã—Å–ª–∞.\n\n'
        f'üéôÔ∏è*–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏* - –æ–∑–≤—É—á–∏–≤–∞–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª–æ–º. –û–∑–≤—É—á–∏—Ç—å –º–æ–∂–Ω–æ –¥–≤—É–º—è —Å–ø–æ—Å–æ–±–∞–º–∏:\n1)–ò—Å–ø–æ–ª—å–∑—É—è –≥–æ—Ç–æ–≤—ã–µ –≥–æ–ª–æ—Å–∞\n2)–ò—Å–ø–æ–ª—å–∑—É—è –ª—é–±–æ–π –≥–æ–ª–æ—Å –≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ–±—Ä–∞–∑—Ü–∞\n\n'
        f'–ï—Å–ª–∏ –µ—Å—Ç—å –∫–∞–∫–∏–µ-–ª–∏–±–æ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞ –±–æ—Ç–∞, –Ω–∞–ø–∏—à–∏—Ç–µ /help',
        reply_markup=kb.main,
        parse_mode="Markdown"
    )

@router.message(Command('help'))
async def get_help(message: Message):
    await message.answer(
        f'–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ø–∏–∫–µ—Ä–æ–≤ –Ω–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É *–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—è*. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ —Ñ–∞–π–ª –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç—É.\n\n'
        f'–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –∏ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –≤–∞–º–∏ —Ç–µ–∫—Å—Ç. –ó–∞—Ç–µ–º –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –∫–Ω–æ–ø–∫—É *–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã* –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π —Ä–∞–±–æ—Ç—ã.\n\n'
        f'–î–ª—è –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –æ–¥–∏–Ω –∏–∑ –¥–≤—É—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤. –ü—Ä–∏ –≤—ã–±–æ—Ä–µ –≥–æ—Ç–æ–≤–æ–≥–æ –≥–æ–ª–æ—Å–∞ –≤—ã –ø–æ–ª—É—á–∏—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª –∫–∞–∫ –±–æ—Ç –∑–∞–≤–µ—Ä—à–∏—Ç —Å–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏. –ê –¥–ª—è –æ–∑–≤—É—á–∫–∏ —Å–≤–æ–∏–º –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –æ–±—Ä–∞–∑–µ—Ü –≥–æ–ª–æ—Å–∞ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –Ω—É–∂–Ω—ã–º –≤–∞–º –≥–æ–ª–æ—Å–æ–º –±–æ—Ç—É.\n\n',
        parse_mode="Markdown"
    )

@router.message(F.text == '–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—è')
async def get_transcribe(message: Message, state: FSMContext):
    await message.answer("–û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∞—É–¥–∏–æ –∏–ª–∏ –≤–∏–¥–µ–æ —Ñ–∞–π–ª")
    await state.set_state(UserState.waiting_for_transcribe)


@router.message(F.text == '–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã')
async def show_texts(message: Message):
    texts = await db.get_texts(message.from_user.id, with_speakers=True)
    if not texts:
        await message.answer("–ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.")
        return
    
    await db.set_current_index(message.from_user.id, 0)
    await message.answer(
        f"–¢–µ–∫—Å—Ç 1 –∏–∑ {len(texts)}:\n\n{texts[0]}",
        reply_markup=kb.text_nav
    )

@router.message(UserState.waiting_for_transcribe, F.voice | F.video | F.audio)
async def get_audio(message: Message, bot: Bot, state: FSMContext):
    try:
        if message.video:
            file = await bot.get_file(message.video.file_id)
            ext = ".mp4"
        elif message.voice:
            file = await bot.get_file(message.voice.file_id)
            ext = ".ogg"
        elif message.audio:
            file = await bot.get_file(message.audio.file_id)
            ext = ".mp3"
        else:
            await message.answer("–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è.")
            return

        with tempfile.NamedTemporaryFile(suffix=ext, delete=False) as temp_file:
            file_path = temp_file.name
            await bot.download_file(file.file_path, destination=file_path)

        if message.video:
            video = VideoFileClip(file_path)
            audio_path = file_path + ".wav"
            video.audio.write_audiofile(audio_path)
            video.close()
            os.unlink(file_path)
            file_path = audio_path

        if file_path.endswith('.ogg'):
            audio = AudioSegment.from_ogg(file_path)
            wav_path = file_path + ".wav"
            audio.export(wav_path, format="wav")
            os.unlink(file_path)
            file_path = wav_path

        await message.answer("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É—é –∏ –¥–∏–∞—Ä–∏–∑–∏—Ä—É—é...")
        diarized_text, raw_text = transcribe_and_diarize(file_path)
        
        last_transcription[message.from_user.id] = diarized_text
        last_raw_transcription[message.from_user.id] = raw_text
        
        await message.answer(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å –¥–∏–∫—Ç–æ—Ä–∞–º–∏:\n\n{diarized_text}", 
                           reply_markup=kb.get_post_transcribe_keyboard())
        await state.clear()

    except Exception as e:
        await message.answer(f"–û—à–∏–±–∫–∞: {str(e)}")
    finally:
        if os.path.exists(file_path):
            os.unlink(file_path)
        wav_path = file_path + ".wav"
        if os.path.exists(wav_path):
            os.unlink(wav_path)

@router.callback_query(F.data == 'generate_tts')
async def request_voice_acting(callback: CallbackQuery, state: FSMContext):
    await callback.message.answer(
        "–í—ã–±–∏—Ä–µ—Ç–∏–µ —Å–ø–æ—Å–æ–± –æ–∑–≤—É—á–∫–∏ —Ç–µ–∫—Å—Ç–∞",
        reply_markup=kb.voice_acting
    )

@router.callback_query(F.data == 'ready_voice')
async def request_ready_voice(callback: CallbackQuery, bot: Bot):
    current_index = await db.get_current_index(callback.from_user.id)
    texts = await db.get_texts(callback.from_user.id, with_speakers=False)
    
    if not texts or current_index >= len(texts):
        await callback.message.answer("–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–∑–≤—É—á–∫–∏.")
        return
    
    await callback.message.answer("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∞—É–¥–∏–æ...")

    output_path = f"tts_output_{callback.from_user.id}.mp3"

    tts.tts_to_file(
        text=texts[current_index],
        file_path=output_path,
        speaker="Ferran Simen",
        language="ru",
        split_sentences=True
    )
    with open(output_path, 'rb') as audio_file:
            audio_bytes = audio_file.read()
            input_file = BufferedInputFile(
            file=audio_bytes,
            filename="—Ç–µ–∫—Å—Ç.mp3"
        )   
    await bot.send_audio(
        chat_id=callback.message.chat.id,
        audio=input_file,
    )

    if os.path.exists(output_path):
        os.unlink(output_path)

@router.callback_query(F.data == 'voice_sample')
async def request_voice_sample(callback: CallbackQuery, state: FSMContext):
    current_index = await db.get_current_index(callback.from_user.id)
    texts = await db.get_texts(callback.from_user.id, with_speakers=False)
    
    if not texts or current_index >= len(texts):
        await callback.message.answer("–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ–∑–≤—É—á–∫–∏.")
        return
    
    last_text_for_tts[callback.from_user.id] = {
        'text': texts[current_index],
        'message_id': callback.message.message_id
    }
    
    await callback.message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª –∫–∞–∫ –æ–±—Ä–∞–∑–µ—Ü –≥–æ–ª–æ—Å–∞.")
    await state.set_state(UserState.waiting_for_tts)


@router.message(UserState.waiting_for_tts, F.voice | F.audio)
async def handle_voice_sample(message: Message, bot: Bot, state: FSMContext):
    if message.from_user.id not in last_text_for_tts:
        return
    
    try:
        if message.voice:
            file = await bot.get_file(message.voice.file_id)
            ext = ".ogg"
        elif message.audio:
            file = await bot.get_file(message.audio.file_id)
            ext = ".mp3"
        
        with tempfile.NamedTemporaryFile(suffix=ext, delete=False) as temp_file:
            voice_sample_path = temp_file.name
            await bot.download_file(file.file_path, destination=voice_sample_path)
        
        if ext == ".ogg":
            audio = AudioSegment.from_ogg(voice_sample_path)
            wav_path = voice_sample_path + ".wav"
            audio.export(wav_path, format="wav")
            os.unlink(voice_sample_path)
            voice_sample_path = wav_path
        
        text_data = last_text_for_tts[message.from_user.id]
        text_to_speak = text_data['text']
        await message.answer("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∞—É–¥–∏–æ...")
        output_path = f"tts_output_{message.from_user.id}.mp3"
        tts.tts_to_file(
            text=text_to_speak,
            file_path=output_path,
            speaker_wav=voice_sample_path,
            language="ru"
        )

        with open(output_path, 'rb') as audio_file:
            audio_bytes = audio_file.read()
            input_file = BufferedInputFile(
            file=audio_bytes,
            filename="—Ç–µ–∫—Å—Ç.mp3"
        )   
        await bot.send_audio(
            chat_id=message.chat.id,
            audio=input_file,
        )
        
    except Exception as e:
        await message.answer(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {str(e)}")
    finally:
        del last_text_for_tts[message.from_user.id]
        if os.path.exists(voice_sample_path):
            os.unlink(voice_sample_path)
        if os.path.exists(output_path):
            os.unlink(output_path)
        await state.clear()

@router.callback_query(F.data == 'save_text')
async def save_text_callback(callback: CallbackQuery):
    diarized_text = last_transcription.get(callback.from_user.id)
    raw_text = last_raw_transcription.get(callback.from_user.id)
    if not diarized_text or not raw_text:
        await callback.message.answer("–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.")
        return
    
    await db.save_text(
        callback.from_user.id,
        diarized_text,
        raw_text,
        username=callback.from_user.username,
        full_name=callback.from_user.full_name
    )
    await callback.message.answer("–¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω")

@router.callback_query(F.data == 'prev_text')
async def prev_text(callback: CallbackQuery):
    texts = await db.get_texts(callback.from_user.id, with_speakers=True)
    if not texts:
        await callback.message.answer("–ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.")
        return
    
    current_index = await db.get_current_index(callback.from_user.id)
    new_index = max(0, current_index - 1)
    
    await db.set_current_index(callback.from_user.id, new_index)
    await callback.message.edit_text(
        f"–¢–µ–∫—Å—Ç {new_index+1} –∏–∑ {len(texts)}:\n\n{texts[new_index]}",
        reply_markup=kb.text_nav
    )


@router.callback_query(F.data == 'next_text')
async def next_text(callback: CallbackQuery):
    texts = await db.get_texts(callback.from_user.id, with_speakers=True)
    if not texts:
        await callback.message.answer("–ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.")
        return
    
    current_index = await db.get_current_index(callback.from_user.id)
    new_index = min(len(texts) - 1, current_index + 1)
    
    await db.set_current_index(callback.from_user.id, new_index)
    await callback.message.edit_text(
        f"–¢–µ–∫—Å—Ç {new_index+1} –∏–∑ {len(texts)}:\n\n{texts[new_index]}",
        reply_markup=kb.text_nav
    )

@router.callback_query(F.data == 'summarize_current')
async def summarize_current(callback: CallbackQuery):
    current_index = await db.get_current_index(callback.from_user.id)
    texts = await db.get_texts(callback.from_user.id, with_speakers=False)
    
    if not texts or current_index >= len(texts):
        await callback.message.answer("–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏.")
        return
    
    text = texts[current_index]
    await callback.message.answer("–°—É–º–º–∞—Ä–∏–∑–∏—Ä—É—é...")

    try:
        input_length = len(text.split())
        max_len = int(input_length * 0.9)
        min_len = int(input_length * 0.6)

        summarizer = pipeline("summarization", model="IlyaGusev/rut5_base_sum_gazeta", device=0)
        result = summarizer(text, max_length=max_len, min_length=min_len)
        await callback.message.answer(f'–†–µ–∑—É–ª—å—Ç–∞—Ç —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:\n\n{result[0]["summary_text"]}')
    except Exception as e:
        await callback.message.answer(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏: {str(e)}")

@router.callback_query(F.data == 'show_raw_text')
async def show_raw_text(callback: CallbackQuery):
    current_index = await db.get_current_index(callback.from_user.id)
    texts = await db.get_texts(callback.from_user.id, with_speakers=False)
    
    if not texts or current_index >= len(texts):
        await callback.message.answer("–ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.")
        return
    
    await callback.message.answer(
        f"–¢–µ–∫—Å—Ç {current_index+1} –±–µ–∑ –¥–∏–∫—Ç–æ—Ä–æ–≤:\n\n{texts[current_index]}"
    )