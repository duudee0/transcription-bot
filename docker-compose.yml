#  docker compose up

services:
  rabbitmq:
    image: rabbitmq:management
    restart: always
    environment:
      RABBITMQ_DEFAULT_USER: guest
      RABBITMQ_DEFAULT_PASS: guest
      #- RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS=-rabbit disk_free_limit 2147483648
    volumes:
      - ./rabbitmq:/var/lib/rabbitmq
    ports:
      - "15672:15672"  # management UI
      - "5672:5672"
    networks:
      - internal

  # redis:
  #   image: redis:8.2.2
  #   ports:
  #     - "6379:6379"
  #   networks:
  #     - internal

  # postgres:
  #   image: postgres:18.0
  #   environment:
  #     POSTGRES_USER: pguser
  #     POSTGRES_PASSWORD: pgpass
  #     POSTGRES_DB: managerdb
  #   volumes:
  #     - pgdata:/var/lib/postgresql/data
  #   networks:
  #     - internal

  gigachat-service:
    build:
      context: ./
      dockerfile: models/gigachat/Dockerfile
    environment:
      - PORT=8000
      - GIGACHAT_TOKEN=${GIGACHAT_TOKEN}
      - GIGACHAT_MODEL=GigaChat
      - GIGACHAT_VERIFY_SSL=False
    ports:
      - "8001:8000"   # Different port to avoid conflict
    command: sh -c "sleep 7 && exec python main.py"
    networks:
      - internal


  llm-service:
    build:
      context: ./
      dockerfile: models/testing/Dockerfile
    environment:
      - PORT=8000
    ports:
      - "8000:8000"   # только для локальной разработки; в prod можно убрать
    # depends_on:
    #   - redis
    # Это проверка "здоровья" контейнера
    # healthcheck:
    #   test: ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"]
    #   interval: 5s
    #   timeout: 3s
    #   retries: 5
    command: sh -c "sleep 7 && exec python main.py"
    networks:
      - internal

  # manager:
  #   build:
  #     context: ./manager
  #     dockerfile: Dockerfile
  #   environment:
  #     - RABBIT_URL=amqp://guest:guest@rabbitmq:5672/
  #     - LLM_URL=http://llm-service:8000/api/v1/infer
  #   depends_on:
  #     - rabbitmq
  #     - llm-service
  #     - postgres
  #     - redis
  #   networks:
  #     - frontend
  #     - internal

  worker:
    build:
      context: .
      dockerfile: worker/Dockerfile
    environment:
      - RABBIT_URL=amqp://guest:guest@rabbitmq:5672/
      - LLM_URL=http://llm-service:8000/api/v1/infer
    depends_on:
      - rabbitmq
      #- llm-service
    command: sh -c "sleep 7 && exec python main.py"

    networks:
      - internal

  wrapper:
    build:
      context: .
      dockerfile: wrapper/Dockerfile
    environment:
      - RABBIT_URL=amqp://guest:guest@rabbitmq:5672/
      - PORT=8003
    ports:
      - "8003:8003"   # только для локальной разработки; в prod можно убрать      
    depends_on:
      - rabbitmq
      #- llm-service
    command: sh -c "sleep 7 && exec python main.py"

    networks:
      - internal
      - frontend


  bot:
    build:
      context: .
      dockerfile: telegram-bot/Dockerfile
    container_name: telegram-bot
    depends_on:
      - rabbitmq
      - wrapper
    environment:
      TELEGRAM_TOKEN: ${TELEGRAM_TOKEN}
      WRAPPER_URL: "http://wrapper:8003"
      BOT_CALLBACK_HOST: "0.0.0.0"
      BOT_CALLBACK_PORT: "9000"
      BOT_CALLBACK_HOST_DOCKER: "telegram-bot"
      # Этот URL вкладывается в задачи как client_callback_url (wrapper будет POSTить сюда)
      CLIENT_CALLBACK_URL_FOR_WRAPPER: "http://telegram-bot:9000/client/webhook"
      POLL_INTERVAL: "1.0"
      GLOBAL_TIMEOUT: "60"
    ports:
      - "9000:9000"  # если вы хотите пробросить для отладки
    networks:
      - frontend
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/health"]
      interval: 10s
      timeout: 5s
      retries: 5

networks:
  frontend:
  internal:

volumes:
  pgdata:
